#!/usr/bin/env python3

import argparse
import math
import os
import sys
import shutil
import pysam
import pyfaidx
from libs import max_is_calc

def eprint(*args, **kwargs):
    "Prints messages to stderr"
    print(*args, file=sys.stderr, **kwargs)

cmd_parser = argparse.ArgumentParser(description=   'SurEVirus, a virus'
                                                    ' integration caller.')
cmd_parser.add_argument('fq1',
                        help='Input Fwd Reads in fastq format.')
cmd_parser.add_argument('fq2',
                        help='Input Rev Reads in fastq format.')
cmd_parser.add_argument('workdir', help='Working directory for SurVirus to use.')
cmd_parser.add_argument('host_reference',
                        help='Reference of the host organism in FASTA format.')
cmd_parser.add_argument('virus_reference',
                        help='References of a list of viruses in FASTA format.')
cmd_parser.add_argument('host_and_virus_reference',
                        help='Joint references of host and viruses.')
cmd_parser.add_argument('--threads', type=int, default=1,
                        help='Number of threads to be used.')
cmd_parser.add_argument('--bwa', default='bwa', help='BWA path.')
cmd_parser.add_argument('--bedtools', help='Bedtools path.', default='bedtools')
cmd_parser.add_argument('--samtools', help='Samtools path.', default='samtools')
cmd_parser.add_argument('--dust', help='Dust path.', default='dust')
cmd_parser.add_argument('--excluded_regions_bed', \
                        help=   'Can use to exclude repetetive regions or'
                                ' uninteresting portions of the genome')
cmd_parser.add_argument('--minClipSize', type=int, default=20, \
                        help='Min size for a clip to be considered.')
cmd_parser.add_argument('--maxAltAln', type=int, default=6,
                        help='Max number of alternative alignments for a \
                                read to be considered')
cmd_parser.add_argument('--maxSCDist', type=int, default=10,
                        help='Max SC distance.')
cmd_parser.add_argument('--clean_first', action='store_true',
                        help=   'Before processing any files already in the'
                                ' working directory are erased - By default'
                                ' SurEVirus will only perform incomplete steps')
cmd_parser.add_argument('--isParams',
                        help=   '4 comma spearated values defining the read length'
                                ' as well mean, std.dev, and upper std.dev'
                                ' for insert size;'
                                ' uppSD = √[mean(x_i-μ)^2] ∀ x_i > μ;'
                                ' Estimated from the data by default;'
                                ' Specifying improves reproducability' )
cmd_parser.add_argument('--max_is_upper_bound', type=int, default=1000,
                        help = 'The largest insert size to consider'
                        )
cmd_args = cmd_parser.parse_args()

SURVIRUS_PATH = os.path.dirname(os.path.realpath(__file__))
SURVIRUS_BIN_PATH = os.path.join(SURVIRUS_PATH,"bin")
SURVIRUS_UTIL_PATH = os.path.join(SURVIRUS_PATH,"util")

PATH_DICT = { nm : os.path.join(cmd_args.workdir,path) for nm,path in {
        "adjRes"    : "results.remapped.txt",
        "config"    : "config.txt",
        "ctgLen"    : "contig_lengths.tab",
        "ctgMap"    : "contig_map",
        "edges"	    : "edges.tab",
        "discard"   : "results.discarded.txt",
        "filtRes"   : "results.remapped.t1.txt",
        "fqBam"     : os.path.join("bam_0","retained-pairs.namesorted.bam"),
        "fqStats"   : os.path.join("bam_0","stats.txt"),
        "fqSrtBam"  : os.path.join("bam_0","retained-pairs.remapped.cs.bam"),
        "frawRes"   : "results.t1.txt",
        "hBed"      : "h.bed",
        "hSeq"      : "host_bp_seqs.fa",
        "juncCand"  : "junction-candidates.bed",
        "regSeq"    : "regions.fna",
        "regCand"   : "region-candidates.bed",
        "readSeq"   : "edge_reads.fna",
        "rawRes"    : "results.txt",
        "vBed"      : "v.bed",
        "vNames"    : "virusNames.list",
        "vSeq"      : "virus_bp_seqs.fa"
    }.items()
}

BIN_DICT = { nm : os.path.join(SURVIRUS_BIN_PATH,nm) for nm in (
        "cleanbam", "addX2tag", "enumerate_edges",
        "cluster_junctions", "edge_mapper", "extract_clips", "extract_regions",
        "filter", "isolate_relevant_pairs", "isolate_relevant_pairs_fq" )
}
UTIL_DICT = { nm : os.path.join(SURVIRUS_UTIL_PATH,path) for nm,path in {
        "adjCov"    : "adjustCoverage.awk",
        "e2eBed"    : "edge2edgeRegionBed.awk",
        "extERead"  : "extractEdgeReads.awk",
        "splitCBed" : "splitCallBed.awk"
    }.items()
}

BATCH_SIZE=100000000
MAX_XA=999999

def execute(cmd):
    "Logs and executes a command"
    eprint("Executing:", cmd)
    if not os.system(cmd) == 0:
        eprint("Execution Failed - Exiting")
        sys.exit(1)

def missing_file(path):
    "Checks if a file needs to be created"
    return not os.path.isfile(path)

def filter_bed(path,strict_filter):
    "filters excluded regions from a bed file"
    a_flag = "-A" if strict_filter else ""
    tmp_file = path + ".tmp"
    bedtools_cmd = (f"{cmd_args.bedtools} subtract {a_flag} -a {path}"
                    f" -b {cmd_args.excluded_regions_bed} > {tmp_file}" )
    execute(bedtools_cmd)
    os.replace(tmp_file, path)

def get_max_is(file):
    "parses a stats file and returns the maxIS value"
    with open(file, encoding ="utf-8") as stats:
        val = stats.readline().strip().split()[1]
    if(val > cmd_args.max_is_upper_bound):
        val = cmd_args.max_is_upper_bound;
    return val

def get_max_rl(file):
    "parses a config file and returns the max Read length value"
    with open(file, encoding ="utf-8") as config:
        for line in config:
            tag,value = line.strip().split()
            if tag == "read_len":
                return value
    return None


def parse_is_param():
    "parses a string and returns the insert size parameters"
    params = cmd_args.isParams.split(',')
    if len(params) < 4:
        eprint("isParams requires 4 comma separated values,"
                " readLen,mean,SD,upperSD")
        sys.exit(1)
    return (float(x) for x in params)


#Remove workdir if requested
if cmd_args.clean_first:
    shutil.rmtree(cmd_args.workdir,ignore_errors=True)
#Create workdir
if not os.path.exists(cmd_args.workdir):
    os.makedirs(cmd_args.workdir)
# Create config file in workdir
if missing_file(PATH_DICT["config"]):
    with open(PATH_DICT["config"], "w", encoding ="utf-8") as config_file:
        config_file.write(f"threads {cmd_args.threads}\n")
        config_file.write(f"min_sc_size {cmd_args.minClipSize}\n")
        config_file.write(f"max_sc_dist {cmd_args.maxSCDist}\n")
        config_file.write(f"max_alt_aln {cmd_args.maxAltAln}\n")
# Generate general distribution of insert sizes
if missing_file(PATH_DICT["ctgMap"]):
    with open(PATH_DICT["ctgMap"], "w", encoding= "utf-8") as contig_map:
        reference_fa = pyfaidx.Fasta(cmd_args.host_and_virus_reference)
        i = 1
        for k in list(reference_fa.keys()):
            contig_map.write(f"{k} {i}\n")
            i += 1
# count viruses
reference_fa = pyfaidx.Fasta(cmd_args.virus_reference)
n_viruses = len(list(reference_fa.keys()))
#Store the virusIDs
if missing_file(PATH_DICT["vNames"]):
    with open(PATH_DICT["vNames"],"w",encoding="utf-8") as virus_names:
        for key in reference_fa.keys():
            virus_names.write(f"{key}\n")
#Store the lengths of all contigs
if missing_file(PATH_DICT["ctgLen"]):
    with pyfaidx.Fasta(cmd_args.host_and_virus_reference) as joint_ref, \
         open(PATH_DICT["ctgLen"],"w",encoding="utf-8") as contig_lengths:
        for key,seq in joint_ref.items():
            contig_lengths.write(f"{key}\t{seq.unpadded_len}\n")
#Construct Bam workspace for fastq input
bam_workspace = os.path.join(cmd_args.workdir,"bam_0")
path_dict = { nm : os.path.join(bam_workspace,path) for nm,path in {
        "rfq1"  : "retained-pairs_1.fq",
        "rfq2"  : "retained-pairs_2.fq",
        "stats" : "stats.txt"
    }.items()
}
if not os.path.exists(bam_workspace):
    os.makedirs(bam_workspace)
#Either get cmd line args, or estimate read len and insert size
if cmd_args.isParams is not None:
    max_read_len,mean_is,sd_is,usd_is = parse_is_param()
    max_is = int(math.ceil(mean_is + 5 * usd_is))
    if(max_is > cmd_args.max_is_upper_bound):
        max_is = cmd_args.max_is_upper_bound;
    max_read_len = int(max_read_len)
    if get_max_rl(PATH_DICT["config"]) is None: 
        with open(PATH_DICT["config"], "a", encoding="utf-8") as config_file:
            config_file.write(f"read_len {max_read_len}")
    if(missing_file(path_dict["stats"])):
        with open(path_dict["stats"], "w", encoding="utf-8") as stat_file:
            stat_file.write(f"max_is {max_is}\n")
elif missing_file(path_dict["stats"]):
    max_read_len, max_is = \
        max_is_calc.get_max_is_from_fq(cmd_args.workdir, cmd_args.fq1, \
        cmd_args.fq2, cmd_args.host_and_virus_reference, cmd_args.bwa, \
        cmd_args.threads)
    if(max_is > cmd_args.max_is_upper_bound):
        max_is = cmd_args.max_is_upper_bound;
    with open(path_dict["stats"], "w", encoding="utf-8") as stat_file:
        stat_file.write(f"max_is {max_is}\n")
    with open(PATH_DICT["config"], "a", encoding="utf-8") as config_file:
        config_file.write(f"read_len {max_read_len}\n")
else:
    max_is = get_max_is(path_dict["stats"])

    max_read_len = get_max_rl(PATH_DICT["config"])



isolate_cmd = ( f"{BIN_DICT['isolate_relevant_pairs_fq']}"
                f" {cmd_args.fq1} {cmd_args.fq2}"
                f" {cmd_args.host_reference}"
                f" {cmd_args.virus_reference} {cmd_args.workdir}"
                f" {bam_workspace}" )
if ( missing_file(path_dict["rfq1"]) or missing_file(path_dict["rfq2"]) ):
    execute(isolate_cmd)

#Check if IS sizes have been defined by the user
IS_OPT=""
if cmd_args.isParams is not None:
    _, mean_is, sd_is, _ = parse_is_param()
    IS_OPT = f"-I {mean_is},{sd_is}"

#Define function to map clips
def map_clips(prefix, reference):
    "Maps clips with a given prefix to the given reference"
    l_path_dict = { ext : prefix + "." + ext for ext in \
        ( "sai", "full.bam", "aln.bam", "unmapped.fa", "mem.bam", "bam", "cs.bam" )
    }

    bwa_aln_cmd = ( f"{cmd_args.bwa} aln -t {cmd_args.threads} {reference}"
                    f" {prefix}.fa -f {l_path_dict['sai']}" )
    bwa_samse_cmd = (   f"{cmd_args.bwa} samse -n {MAX_XA}"
                        f" {reference} {l_path_dict['sai']} {prefix}.fa |"
                        f" {cmd_args.samtools} view -b -F 2304 >"
                        f" {l_path_dict['full.bam']}" )
    if missing_file(l_path_dict["sai"]):
        execute(bwa_aln_cmd)
    if missing_file(l_path_dict["full.bam"]):
        execute(bwa_samse_cmd)

    filter_unmapped_cmd = ( f"{cmd_args.samtools} view -b -F 4"
                            f" {l_path_dict['full.bam']} > {l_path_dict['aln.bam']}" )
    if missing_file(l_path_dict["aln.bam"]):
        execute(filter_unmapped_cmd)

    dump_unmapped_fa = (f"{cmd_args.samtools} fasta -f 4"
                        f" {l_path_dict['full.bam']} > {l_path_dict['unmapped.fa']}" )
    if missing_file(l_path_dict["unmapped.fa"]):
        execute(dump_unmapped_fa)

    bwa_mem_cmd = ( f"{cmd_args.bwa} mem -t {cmd_args.threads}"
                    f" -h {MAX_XA}"
                    f" -K {BATCH_SIZE} {IS_OPT} {reference}"
                    f" {l_path_dict['unmapped.fa']} |"
                    f" {cmd_args.samtools} view -b -F 2308 >"
                    f" {l_path_dict['mem.bam']}" )

    if missing_file(l_path_dict["mem.bam"]):
        execute(bwa_mem_cmd)

    filt_expr = f"[X2] <= {cmd_args.maxAltAln}"
    merge_cmd = (   f"{cmd_args.samtools} cat {l_path_dict['aln.bam']}"
                    f" {l_path_dict['mem.bam']} |"
                    f" {BIN_DICT['addX2tag']} - - |"
                    f" {cmd_args.samtools} view -b -e '{filt_expr}'"
                    f" -o {l_path_dict['bam']}"
                )
    if missing_file(l_path_dict["bam"]):
        execute(merge_cmd)

    if missing_file(l_path_dict["cs.bam"]):
        pysam.sort("-@", str(cmd_args.threads), "-o",   f"{l_path_dict['cs.bam']}",
                                                        f"{l_path_dict['bam']}")

#All the files which we will be working with
path_dict = { nm : os.path.join(bam_workspace,path) for nm,path in {
        "hAnchor"   : "host-anchors.bam",
        "hClip"     : "host-clips.cs.bam",
        "hFasta"    : "host-clips.fa",
        "nsrtBam"   : "retained-pairs.namesorted.bam",
        "psrtBam"   : "retained-pairs.remapped.cs.bam",
        "rawBam"    : "retained-pairs.remapped.bam",
        "rfq1"      : "retained-pairs_1.fq",
        "rfq2"      : "retained-pairs_2.fq",
        "vAnchor"   : "virus-anchors.bam",
        "vClip"     : "virus-clips.cs.bam",
        "vFasta"    : "virus-clips.fa"
    }.items()
}

#Map the reads to the joint reference
bwa_cmd = ( f"{cmd_args.bwa} mem -t {cmd_args.threads} -K {BATCH_SIZE}"
            f" -h {MAX_XA} {IS_OPT}"
            f" {cmd_args.host_and_virus_reference}"
            f" {path_dict['rfq1']} {path_dict['rfq2']} | "
            f" {cmd_args.samtools} sort -n - >"
            f" {path_dict['rawBam']}"
            )
if missing_file(path_dict["rawBam"]):
    execute(bwa_cmd)
filt_expr = f"[X2] <= {cmd_args.maxAltAln} && [Y2] <= {cmd_args.maxAltAln}"
cleanbam_cmd = (   f" {cmd_args.samtools} fixmate -m {path_dict['rawBam']} - |"
                    f" {BIN_DICT['cleanbam']} - - |"
                    f" {cmd_args.samtools} view -b -e '{filt_expr}' "
                    f" -o {path_dict['nsrtBam']}"
                )
if missing_file(path_dict["nsrtBam"]):
    execute(cleanbam_cmd)
#Position sort
samtools_sort_cmd = (   f"{cmd_args.samtools} sort -@ {cmd_args.threads}"
                        f" -o {path_dict['psrtBam']} {path_dict['nsrtBam']}" )
if missing_file(path_dict["psrtBam"]):
    execute(samtools_sort_cmd)
#Pull clips out
extract_clips_cmd = (   f"{BIN_DICT['extract_clips']}"
                        f" {cmd_args.virus_reference}"
                        f" {cmd_args.workdir} {bam_workspace}" )
if any(missing_file(path_dict[x]) for x in ("vAnchor", "hAnchor", "vFasta", "hFasta")):
    execute(extract_clips_cmd)
# map virus clips
if missing_file(path_dict["vClip"]):
    map_clips(f"{bam_workspace}/virus-clips", cmd_args.host_reference)
# map host clips
if missing_file(path_dict["hClip"]):
    map_clips(f"{bam_workspace}/host-clips", cmd_args.virus_reference)

#Extract candidate host and viral positions
extract_regions_cmd = ( f"{BIN_DICT['extract_regions']}"
                        f" {cmd_args.virus_reference}"
                        f" {cmd_args.workdir} {bam_workspace}" )
if missing_file(PATH_DICT["juncCand"]):
    execute(extract_regions_cmd)
    if cmd_args.excluded_regions_bed is not None:
        filter_bed(PATH_DICT['juncCand'],strict_filter=True)
# Collapse Junctions together into regions
cluster_junctions_cmd = (   f"{BIN_DICT['cluster_junctions']}"
                            f" {cmd_args.virus_reference}"
                            f" {cmd_args.workdir} {bam_workspace}" )
if missing_file(PATH_DICT["regCand"]):
    execute(cluster_junctions_cmd)
    if cmd_args.excluded_regions_bed is not None:
        filter_bed(PATH_DICT['regCand'],strict_filter=False)
## Pair up host-viral regions and assign reads to each edge, filter edges
##  with too few reads
enum_edges_cmd = (  f"{BIN_DICT['enumerate_edges']}"
                    f" {cmd_args.virus_reference} {PATH_DICT['regCand']} >"
                    f" {PATH_DICT['edges']}" )
if missing_file(PATH_DICT["edges"]):
    execute(enum_edges_cmd)
#Get the sequences of the regions of interest
extract_regions_cmd = ( f"{UTIL_DICT['e2eBed']} {PATH_DICT['fqStats']}"
                        f" {PATH_DICT['ctgLen']} {PATH_DICT['edges']} |"
                        f" {cmd_args.bedtools} getfasta -s -name"
                        f" -fi {cmd_args.host_and_virus_reference} -bed - >"
                        f" {PATH_DICT['regSeq']}" )
if missing_file(PATH_DICT['regSeq']):
    execute(extract_regions_cmd)
##Extract the fasta sequences of the reads on the edges
extract_reads_cmd = ( f"{cmd_args.samtools} view {PATH_DICT['fqBam']} |"
                      f" {UTIL_DICT['extERead']} {PATH_DICT['vNames']}"
                      f" {PATH_DICT['edges']} /dev/stdin >"
                      f" {PATH_DICT['readSeq']}" )
if missing_file(PATH_DICT['readSeq']):
    execute(extract_reads_cmd)
#Make the readsx dir
readsx = cmd_args.workdir + "/readsx"
if not os.path.exists(readsx):
    os.makedirs(readsx)
##Edgemapper Command
edge_mapper_cmd = ( f"{BIN_DICT['edge_mapper']} "
                    f" {cmd_args.virus_reference} {cmd_args.workdir}"
                    f" {bam_workspace}" )
if any(missing_file(PATH_DICT[nm]) for nm in ( "rawRes", "hSeq", "vSeq" )):
    execute(edge_mapper_cmd)
##Dust Filter the breakpoint sequences
for side in ("host", "virus"):
    tgtFile = f"{cmd_args.workdir}/{side}_bp_seqs.masked.bed"
    dust_cmd = f"{cmd_args.dust} {cmd_args.workdir}/{side}_bp_seqs.fa > {tgtFile}"
    if missing_file(tgtFile):
        execute(dust_cmd)
####Retreive the breakpoint region coverage
#Pull out a bed formated version of the called breakpoints, separately for host and virus
split_cmd = (   f"{UTIL_DICT['splitCBed']} -v outdir={cmd_args.workdir}"
                f" {PATH_DICT['rawRes']}" )
if any(missing_file(PATH_DICT[nm]) for nm in ( "hBed", "vBed" )):
    execute(split_cmd)
    for nm in ( "hBed", "vBed" ):
        if missing_file(PATH_DICT[nm]): #If there are no LCRs found by dust the file won't be made
            execute(f"touch {PATH_DICT[nm]}")
max_is = get_max_is(PATH_DICT["fqStats"])
calc_coverage_cmd = (   f"{{ {cmd_args.bedtools} slop -s -l {max_is} -r 0"
                        f" -i {PATH_DICT['hBed']} -g {PATH_DICT['ctgLen']};"
                        f" {cmd_args.bedtools} slop -s -l 0 -r {max_is}"
                        f" -i {PATH_DICT['vBed']} -g {PATH_DICT['ctgLen']};"
                        f" }} | {cmd_args.samtools} bedcov -d 1 /dev/stdin "
                        f" {PATH_DICT['fqSrtBam']} | {UTIL_DICT['adjCov']}"
                        f" {PATH_DICT['vNames']} /dev/stdin"
                        f" {PATH_DICT['rawRes']} > {PATH_DICT['adjRes']}" )

if missing_file(PATH_DICT['adjRes']):
    execute(calc_coverage_cmd)
#Filter and make results human readable
filter_cmd = (  f"{BIN_DICT['filter']} {cmd_args.workdir} >"
                f" {PATH_DICT['frawRes']}" )

if missing_file(PATH_DICT['frawRes']):
    execute(filter_cmd)
filter_cmd = (  f"{BIN_DICT['filter']} {cmd_args.workdir} --remapped >"
                f" {PATH_DICT['filtRes']}" )
if missing_file(PATH_DICT['filtRes']):
    execute(filter_cmd)
filter_cmd = ( f"{BIN_DICT['filter']} {cmd_args.workdir} --print-rejected >"
                f" {PATH_DICT['discard']}" )
if missing_file(PATH_DICT['discard']):
    execute(filter_cmd)

eprint("Done")
